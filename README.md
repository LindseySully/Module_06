# Module Overview

The following Module provided a review of web scraping and natural language processing. The following python libraries were leveraged:
* beautifulsoup4 - read and modify the DOM of a webpage - XML parser
* requests - sends a request to the HTTP site of our choosing
* html5lib (optional parser)
* counter - counting our occurances of our tokens/lemmas
* spaCy - for natural language processing
* spacytextblob
* matplotlib.pyplot -  for histogram plotting
* pickle - for writing and reading an article

### About this Module
This module explored requesting, parsing, writing, and reading an HTML article. Then taking the article and using natural language processing to understand the frequency of common words throughout the article and their frequency of occurance. 

# Web Scraping and NLP with Requests, BeautifulSoup, and spaCy

Complete the tasks in the Python Notebook in this repository.
Make sure to add and push the pkl or text file of your scraped html (this is specified in the notebook)

## Rubric

* (Question 1) Article html stored in separate file that is committed and pushed: 1 pt
* (Question 2) Article text is correct: 1 pt
* (Question 3) Correct (or equivalent in the case of multiple tokens with same frequency) tokens printed: 1 pt
* (Question 4) Correct (or equivalent in the case of multiple lemmas with same frequency) lemmas printed: 1 pt
* (Question 5) Correct scores for first sentence printed: 2 pts (1 / function)
* (Question 6) Histogram shown with appropriate labelling: 1 pt
* (Question 7) Histogram shown with appropriate labelling: 1 pt
* (Question 8) Thoughtful answer provided: 1 pt
